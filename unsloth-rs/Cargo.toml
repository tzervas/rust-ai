[package]
name = "unsloth-rs"
version = "1.0.2"
edition = "2021"
rust-version = "1.92"
license = "MIT"
authors = ["Tyler Zervas <tz-dev@vectorweight.com>"]
description = "Rust implementations of transformer building blocks for LLM inference"
repository = "https://github.com/tzervas/unsloth-rs"
keywords = ["transformers", "llm", "machine-learning", "attention", "rust"]
categories = ["science", "mathematics"]

[dependencies]
candle-core = { workspace = true }
candle-nn = { workspace = true }
thiserror = { workspace = true }
tracing = { workspace = true }
bytemuck = { workspace = true }

# Core ternary types from trit-vsa
trit-vsa = { version = "0.3", path = "../trit-vsa" }

# GPU compute - CubeCL for cross-platform GPU kernels (optional to avoid uuid/js-sys conflict)
cubecl = { workspace = true, optional = true }
cubecl-cuda = { workspace = true, optional = true }
# Tensor-core accelerated matmul for Q@K^T and Attn@V operations
# Note: Fallback to manual implementation initially; integrate once validated
# cubek-matmul = { git = "https://github.com/tracel-ai/cubek" }

[dev-dependencies]
criterion = { workspace = true }
proptest = "1.9"
anyhow = { workspace = true }

[features]
default = []
cuda = ["candle-core/cuda", "dep:cubecl", "cubecl/cuda", "dep:cubecl-cuda"]
gpu = ["dep:cubecl"]  # CubeCL without CUDA (for CPU compute)
_phase2_tiled_kernel = []
_ternary_cubecl_todo = []

[lints.rust]
missing_docs = "warn"

[lints.clippy]
pedantic = "warn"

[[bench]]
name = "kernels"
harness = false
